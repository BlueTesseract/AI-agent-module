% Opcje klasy 'iithesis' opisane sa w komentarzach w pliku klasy. Za ich pomoca
% ustawia sie przede wszystkim jezyk i rodzaj (lic/inz/mgr) pracy, oraz czy na
% drugiej stronie pracy ma byc skladany wzor oswiadczenia o autorskim wykonaniu.
\documentclass[polish,shortabstract,inz]{iithesis}

\usepackage[utf8]{inputenc}

%%%%% DANE DO STRONY TYTUŁOWEJ
% Niezaleznie od jezyka pracy wybranego w opcjach klasy, tytul i streszczenie
% pracy nalezy podac zarowno w jezyku polskim, jak i angielskim.
% Pamietaj o madrym (zgodnym z logicznym rozbiorem zdania oraz estetyka) recznym
% zlamaniu wierszy w temacie pracy, zwlaszcza tego w jezyku pracy. Uzyj do tego
% polecenia \fmlinebreak.
\polishtitle{Projekt i implementacja biblioteki ułatwiającej tworzenie\fmlinebreak inteligentnych agentów grających w gry planszowe}
\englishtitle{Python module to support creating AI for board games - design and implementation}
\polishabstract{
Praca ta skupia się na wytłumaczeniu jak używać tytułowego oprogramowania.
Aby ten cel został osiągnięty praca ta w pierwszej kolejności zapewnia niezbędne wprowadzenie teoretyczne.
Zadbano również tutaj o szczegółowe omówienie modułu napisanego w python'ie.
Na potrzeby programistów, dodatkowo można tu znaleźć przykłady pisania oraz używania biblioteki.
}
\englishabstract{
This thesis is about explaining how to use and write programs using python module to support creating AI for board games.
At the beginning of this thesis, theoretical introduction, where used algorithms are described, can be found.
Next chapters are about writing programs using that module.
This thesis also provides quite a lot of examples and explanations for source codes in appendixes.
}
% w pracach wielu autorow nazwiska mozna oddzielic poleceniem \and
\author{Mikołaj Kowalik}
% w przypadku kilku promotorow, lub koniecznosci podania ich afiliacji, linie
% w ponizszym poleceniu mozna zlamac poleceniem \fmlinebreak
\advisor        {dr Paweł Rychlikowski}
%\date          {15.01.2019}                     % Data zlozenia pracy
% Dane do oswiadczenia o autorskim wykonaniu
\transcriptnum  {283476}                     % Numer indeksu
%\advisorgen    {dr. Pawła Rychlikowskiego} % Nazwisko promotora w dopelniaczu
%%%%%

%%%%% WLASNE DODATKOWE PAKIETY
%
%\usepackage{graphicx,listings,amsmath,amssymb,amsthm,amsfonts,tikz}
%
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}
\lstset
{
    language=Python,
    basicstyle=\footnotesize,
    numbers=left,
    stepnumber=1,
    showstringspaces=false,
    tabsize=4,
    breaklines=true,
    breakatwhitespace=false,
}
%%%%% WŁASNE DEFINICJE I POLECENIA
%
%\theoremstyle{definition} \newtheorem{definition}{Definition}[chapter]
%\theoremstyle{remark} \newtheorem{remark}[definition]{Observation}
%\theoremstyle{plain} \newtheorem{theorem}[definition]{Theorem}
%\theoremstyle{plain} \newtheorem{lemma}[definition]{Lemma}
%\renewcommand \qedsymbol {\ensuremath{\square}}
% ...
%%%%%

\begin{document}

%%%%% POCZĄTEK ZASADNICZEGO TEKSTU PRACY

\chapter{Wprowadzenie}
Jednym z naturalnych miejsc do testowania sztucznej inteligencji są gry planszowe.
Na potrzeby kursu sztuczna inteligencja, student miał za zadanie, oprócz testowania, implementowania dużej ilości gier planszowych.
Celem tej pracy jest wyjście na przeciw potrzebom jakie powstały podczas tamtego kursu i opracowanie odpowiedniego modułu napisanego w Pythonie.
Tak więc, podstawowym celem tej pracy jest zapoznanie użytkownika-programisty z obsługą tytułowej biblioteki - która ma ułatwić pewne powtarzalne czynności - z jakimi trzeba się zmierzyć podczas pisania gry planszowej z inteligentnym, komputerowym graczem.
Praca ta zapewnia rozdziały takie jak:
\begin{itemize}
  \item Wprowadzenie teoretyczne - przewidziane dla osób, które chcą poznać w minimalnym stopniu różnice pomiędzy, implementowanymi w pracy, algorytmami przeszukiwania (MiniMax, Alpha-Beta, MCTS).
  \item Rozdział poświęcony opisowi i przykładom użycia biblioteki - znaleźć tu można podrozdziały takie jak:
    \begin{itemize}
      \item Opis środowiska uruchomieniowego.
      \item Omówienie zawartości biblioteki.
      \item Omówienie zasad gier planszowych pojawiających się w pracy.
      \item Omówienie fragmentów kodu, które zostały uznane za potrzebne do wytłumaczenia.
      \item Propozycje dalszego rozwoju biblioteki - zostały tam przedstawione liczne propozycje usprawnień oraz rozbudowy tej biblioteki.
    \end{itemize}
  \item Zakończenie - krótkie podsumowanie całości pracy.
\end{itemize}

W bibliotece tej jak widać większa część pracy skupia się na praktycznym podejściu do używania biblioteki.
Takie podejście zostało wybrane ze względu na to, że implementowane na potrzeby tej pracy algorytmy nie są niczym nowym - zostały omówione już w wielu innych pracach.

Po tym krótkim wprowadzeniu przejdziemy teraz do zapowiadanego wcześniej wprowadzenia teoretycznego.


\chapter{Wprowadzenie teoretyczne}
\section{Sztuczna inteligencja a gry}
Od samego początku istnienia sztucznej inteligencji, gry planszowe były dla niej naturalnym miejscem do testowania i rozwoju.
Dobrym tego dowodem jest, że już w 1951 r. Alan Turing, nie mając dostępu do odpowiedniego komputera napisał program, którego celem było granie w szachy.

Sztuczna inteligencja w grach zawsze wzbudzała duże emocje.
Szczególnie gdy gracze uznawani za najlepszych w swoich czasach w danych grach zostawali pokonywani.
Przykłady takich wydarzeń to:
\begin{itemize}
    \item Pierwsza wygrana komputera Deep Blue z ówczesnym szachowym mistrzem świata Garri Kasparowem
    \item W 2015r. światowej klasy zawodnik w Go, Lee Sedol, przegrywa ze sztuczną inteligencją AlphaGo (od firmy DeepMind)
\end{itemize}

Istnieje jeszcze wiele przykładów sukcesów sztucznej inteligencji nad człowiekiem (np. warcaby), ze względu na cel tej pracy reszta przykładów została pominięta.

Teraz zostanie powiedziane o problemie wyboru ruchu w grach planszowych z perspektywy sztucznej inteligencji.

\section{Problem przeszukiwania w grach planszowych}
Jednym z podstawowych problemów gier planszowych jest problem przeszukiwania.
Na tym etapie biblioteka głównie jest skupiona na pomocy programiście poradzenia sobie właśnie z tym problemem, ale nie tylko.
Na potrzeby tej pracy wybrano trzy algorytmy przeszukiwania: MiniMax, Alpha-Beta oraz Monte Carlo Tree Search, które, od strony praktycznej, omówione są w tym wprowadzeniu.

\section{Drzewo gry}
Zanim jednak zostaną opisane algorytmy, warto jednak opisać sposób patrzenia na rozgrywkę w dowolną grę planszową (z adwersarzem), jako na drzewo możliwych ruchów.

Drzewo gry to sposób prezentacji rozgrywki.
W wierzchołkach tego drzewa znajdują się stany gry.
Dzieci wierzchołka to wszystkie możliwe do wykonania ruchy ze stanu gry, który ten wierzchołek sobą reprezentuje.
Poniżej rysunek takiego drzewa dla gry w kółko i krzyżyk - obrazek znaleziony na wikipedii.


\begin{figure}[H]
  \includegraphics[scale=0.3]{./images/tictactoetree.png}
  \centering
  \caption{kółko i krzyżyk - drzewo gry}
  \label{fig:ox_tree}
\end{figure}

Przy tak rozumianym drzewie gry problem wyboru ruchu sprowadza się do problemu przeszukiwania.
Jednak w odróżnienia do zwykłego przeszukiwania problemem jest przeciwnik - o którym możemy poczynić jedynie niewielkie założenia.
Jednym z rozsądnych założeń jest przyjęcie, że przeciwnik zawsze będzie wybierał najlepszy dla siebie ruch.
Na takim założeniu opiera się właśnie algorytm MiniMax, które będzie teraz omówiony.


\section{Algorytm MiniMax}
\subsection{Pełny algorytm MiniMax}
Algorytm MiniMax w podstawowej wersji (pełny MiniMax) przegląda wszystkie możliwe ruchy i buduje całe drzewo gry.
Algorytm ten zakłada, że zarówno gracz jak i przeciwnik będą wykonywać najlepsze dla siebie, ruchy.
Na podstawie tak zbudowanego drzewa gry algorytm wybiera najlepszy możliwy ruch.
Poniżej algorytm ten zapisany w postaci pseudokodu:

\bigskip
\lstinputlisting{./minimax.pseudocode}

\subsubsection{Wady i zalety}
Poniżej znajduje się streszczenie wad i zalet tego algorytmu.
\newline Wady:
\begin{itemize}
  \item Stosunkowo wolny w działaniu gdy drzewo gry jest duże
  \item Potrzebuje dużo pamięci gdy rozgrywka może mieć bardzo dużo ruchów
  \item Ze względu na dwie pierwsze wady - raczej nie wykorzystywany
\end{itemize}
Zalety:
\begin{itemize}
  \item Podaje optymalne ruchy
  \item Nie wymaga heurystyk
\end{itemize}


\subsection{Algorytm MiniMax z obcięciami}
Algorytm MiniMax z obcięciami działa tak samo jak pełny minimax - z tą różnicą, że gdy algorytm rozbuduje drzewo gry do pewnej wysokości przestaje rozbudowywać i wywołuje funkcję heurystyczną w celu oceny wygranej.
Poniżej algorytm zapisany w pseudokodzie:

\newpage
\lstinputlisting{./minimaxcut.pseudocode}
Jak widać jedyna znacząca zmiana znajduje się w dziesiątej oraz jedenastej lini kodu - zapobiega ona zbytniemu rozgałęzieniu się drzewa.
Zapobieganie zbytniemu rozbudowywaniu drzewa gry polega na sprawdzeniu czy maksymalna zadana głębokość została przekroczona.
W przypadku przekroczenia maksymalnej głębokości oceniamy sytuacje na planszy oraz oceniony w ten sposób stan gry zwracamy jako wynik gry.

\subsubsection{Wady i zalety}
Poniżej podano podsumowanie tego algorytmu - opisując jego wady i zalety.
\newline Wady:
\begin{itemize}
  \item Tak samo wolny w działaniu jak zwykły minimax, głębokość rozwijania drzewa może być jednak ograniczona
  \item Wymaga funkcji oceny stanu gry - czesto stworzenie takiej funkcji jest skomplikowanym zadaniem
\end{itemize}
Zalety:
\begin{itemize}
  \item Można ograniczyć wykorzystanie czasu i pamięci zużywanej przez przez drzewo gry
  \item Dzięki funckji oceny czas działania powinien być szybszy niż w przypadku pełnego MiniMaxa, wynik jednak może się różnić od optymalnego.
\end{itemize}


\section{Algorytm Alpha-Beta}
Na początku warto wspomnienieć fakt, że algorytm Alpha-Beta zwraca dokładnie te same wyniki co MiniMax (algorytmy są sobie teoretycznie równoważne).
Algorytm Aplha-Beta to w praktyce zmodyfikowana wersja MiniMaxa - algorytm ten w porównaniu do minimax wykonuje dodatkowe cięcia.
W praktyce oznacza to, że drzewo będzie mniej rozgałęzione, a samo działanie szybsze (pewne zbędne rozgałęzienia, jak i sprawdzanie są pomijane).
Dodatkowo warto wiedzieć, że ze względu na sposób wykonywania odcięć - algorytm działa szybciej gdy przegląda ruchy w sposób uporządkowany (od najlepszych do najgorszych).
Ta własność algorytmu jest dobrym miejscem do wprowadzania dalszych optymalizacji algorytmów z rodziny minimax.
Jednakże podstawowa wersja nie obejmuje takich udoskonaleń dlatego pominę dalsze rozważania na ten temat.

Z punktu widzenia programisty można z tego algorytmu korzystać jak z MiniMaxa (uwzględniając ograniczenia minimaxa).
Poniżej został zamieszczony algorytm w pseudokodzie - Jak można zobaczyć cały algorytm nie różni się zbytnio od MiniMaxa.

\lstinputlisting{./alphabeta.pseudocode}
Dla uproszczenia zapisu zwracane są tylko wartości alpha i beta - w normalnym wypadku na poziomie zero można zwrócić stan/ruch, który odpowiada końcowym wartościom alpha/beta.

\subsubsection{Wady i zalety}
Poniżej znajdują się wypunktowane wady i zalety tego algorytmu.
\newline Wady:
\begin{itemize}
  \item Jeśli nie chcemy rozbudowywać drzewa do samego końca to wymaga funkcji oceny stanu gry.
\end{itemize}
Zalety:
\begin{itemize}
  \item Dużo szybszy niż MiniMax. Jako przykład można podać implementację na potrzeby tej pracy gry w kółko i krzyżyk. Gra w której grały przeciw sobie algorytmy MiniMax (pełny) trwała 1 minutę, podczas gdy naprzeciw siebie grali gracze Alpha-Beta, rozgrywka trwała 2 sekundy.
  \item Algorytm bardzo dobrze nadaje się też do bardziej złożonych gier. Dobrym tego przykładem są szachy, gdzie algorytm ten po optymalizacjach takich jak odrzucanie bezsensownych ruchów oraz posortowaniu ruchów względem ich jakości, uzyskuje bardzo dobre wyniki i pokonuje ponadprzeciętnych graczy.
\end{itemize}

\section{Trochę o heurystykach}
We wcześniejszych podrozdziałach wspomniano, bez wytłumaczenia, że niektóre algorytmy potrzebują funkcji heurystycznej.

Funkcje heurystyczne w wyżej opisanych algorytmach mają na celu ocenę sytuacji na planszy, gdy maksymalna dopuszczalna głębokość została przekroczona.
Ocena ta w oczywisty sposób jest tylko przybliżona i może ocenić gorsze ruchy jako lepsze - od jakości tej funkcji w dużej mierze zależy jakość odpowiedzi całego algorytmu.
Jednym z najważniejszych ograniczeń takiej funkcji jest to by zwracany wynik mieścił się w przedziale wartości (lost\textunderscore value, win\textunderscore value).
Ograniczenie to ma na celu zapobieganiu sytuacjom takim, że stan, który nie jest stanem końcowym, jest według heurystyki oznaczany jako lepszy.

Prosty przykład heurystyki do gry w warcaby to funkcja, która zlicza pionki gracza i od otrzymanego wyniku odejmuje liczbę pionków przeciwnika.
Przy takiej funkcji można ustalić wartość win\textunderscore value na 10, a lost\textunderscore value na -10.

\section{Algorytm Monte Carlo Tree Search}
Trzecim i ostatnim algorytmem do przeszukiwania z adwersarzem, implementowanym na potrzeby tej pracy, jest Monte Carlo Tree Search.

Algorytm Monte Carlo Tree Search to algorytm, który od pewnego czasu stał się popularny.
Przyczyną tej popularności bez wątpienia jest fakt, że był on przyczyną sukcesu AlphaGo.

Głównym pomysłem jaki się kryje za tym algorytmem jest przeprowadzanie losowych rozgrywek (dwóch graczy wybiera losowe ruchy) i na podstawie wyników takich partii oceniana jest jakosć ruchu.

Algorytm ten często generuje inne odpowiedzi niż MiniMax.
Zostało jednak udowodnione, że przy dużej liczbie symulacji odpowiedź tego algorytmu zbiega do odpowiedzi MiniMax.

Podstawową różnicą w stosunku do Alpha-Beta i innych algorytmów MiniMax'owych jest to, że drzewo jest rozbudowywane stopniowo, a w wierzchołkach drzewa gry przechowywujemy dodatkowo informacje o ilości przeprowadzonych symulacji w danym węźle oraz ilości symulacji zakończonych wygraną.

Sam Algorytm w pętli (na tyle na ile ograniczenia czasowe mu pozwolą) wykonuje cztery podstawowe fazy, w podanej poniżej kolejności:
\begin{itemize}
  \item Selection
  \item Expansion
  \item Simulation
  \item Backpropagation
\end{itemize}
Poniżej rysunek znaleziony na wikipedi, przedstawiający wpomniane cztery fazy.

\begin{figure}[H]
  \includegraphics[scale=0.4]{./images/mcts.png}
  \centering
  \caption{Fazy algorytmu MCTS}
  \label{fig:mcts}
\end{figure}


\subsection{Selection}
Jak sama nazwa wskazuje - w kroku tym algorytm musi wybrać liść z aktualnego drzewa gry.
Na wybranym wierzchołku kolejno będzie wykonywana faza Expansion.
Poniżej pokazany jest przykładowa implementacja tego kroku wraz ze szczegółowym omówieniem (pseudocode).

\lstinputlisting{./mctsselection.pseudocode}

W powyższym kodzie w pierwszych liniach jest zwracany węzeł jeśli od korzenia drzewa dotarliśmy do liścia lub półliścia (czyli taki wierzchołek, w którym istnieją dzieci na których jeszcze nie była przeprowadzana faza symulacji).

W kolejnych liniach znajduje się funkcja eval\textunderscore func, która służy do oceny, w którą stronę idziemy dalej do liścia lub półliścia.
Funkcja ta jest warta uwagi dlatego poniżej znajduje się o nie trochę informacji.

\subsubsection{Trochę o eval\textunderscore func}
Funkcja ta ma pomóc wybrać wierzchołek z danej głębokości, który jest najbardziej obiecujący.
Dobrze jest gdy wzór ten bierze pod uwagę ilość wygranych oraz ilość przeprowadzonych symulacji w danym wierzchołku.
Z powyższego powodu w pracy tej, jako eval\textunderscore func zaimplementowano wzór UCT:

\[ f\left(node\right) = \frac{node.wins}{node.simulations} + \alpha \cdot \sqrt{\frac{\ln{\left(all\_simulations\right)}}{node.simulations}} \]

\( \alpha \) to parametr, który według zaleceń równy jest \( \sqrt{2} \), w praktyce jego wartość dobierana jest podczas testów.

Zauważmy, że lewa strona sumy przyjmuje dużą wartość gdy w danym węźle jest dużo wygranych.
Prawa strona sumy z kolei przyjmuje duże wartości gdy w danym węźle przeprowadzono małą ilość symulacji.
Przy takim przedstawieniu sumy widać, że parametr \( \alpha \) odpowiada za to co jest bardziej istotne przy wyborze kolejnego wierzchołka do ekspansji - duża ilość wygranych, czy mała ilość przeprowadzaonych symulacji w danym węźle.

Następny w kolejności krok to Expansion - opisany poniżej.

\subsection{Expansion}
Celem tego kroku jest rozbudowanie wierzchołka, który jest liściem lub półliściem.
Rozbudowanie, lub inaczej ekspansja, polega na rozbudowaniu kolejnego poziomu głębokości drzewa (z danego wierzchołka).

Poniżej zaprezentowano przykładową implementację tego kroku (pseudokod).

\lstinputlisting{./mctsexpansion.pseudocode}

W fazie selection wybrany wierzchołek jest liściem lub półliściem.
Przypadek liścia jest obsłużony w pierwszej kolejności - inicjalizujemy dzieci węzła i wybieramy losowy niezainicjalizowany węzeł.
Przypadek półliścia to zwyczajny losowy wybór losowego, niesymulowanego jeszcze dziecka.

\subsection{Simulation}
W tym kroku symulujemy losową rozgrywkę z danego stanu do końca.
Poniżej, w pseudokodzie, przedstawiono przykładową implementację.

\lstinputlisting{./mctssimulation.pseudocode}

\subsection{Backpropagation}
W kroku tym aktualizujemy drzewo na podstawie wyniku uzyskanego w poprzednim kroku.

\lstinputlisting{./mctsback.pseudocode}

Jak widać w tej fazie algorytmu wchodzimy w górę drzewa aktualizując liczbę symulacji oraz wygranych.

Powyższe cztery kroki są powtarzane w kółko aż wykorzystają wyznaczony czas.
Po zakończeniu czasu przewidzianego na ruch zwracane jest dziecko korzenia (ruch), gdzie przeprowadzono największą ilość symulacji (niekoniecznie ten, który miał największy współczynnik wygranych).

\subsubsection{Wady i zalety}
Wady:
\begin{itemize}
  \item Istnieją gry w których losowa rozgrywka może trwać bardzo długo
  \item Szczególnie przy majej liczbie symulacji łatwo można otrzymać ruch nieoptymalny, niskiej jakości
\end{itemize}
Zalety:
\begin{itemize}
  \item Łatwo ograniczyć czasowo jego wykonanie (przez odpowiednią liczbę symulacji)
  \item Nie wymaga heurystyki - losowe rozgrywki spełniają tę rolę
  \item Dobrze nadaje się do gier trudnych, złożonych - gdzie nie są znane dobre strategie (np. Go)
\end{itemize}

\section{Podsumowanie}
Powyżej zaprezentowano podstawowe wersje algorytmów.
Niemniej jednak algorytmy te można znacznie usprawnić - poprzez liczne optymalizacji.
Część z tych optymalizacji można znaleźć w końcowej części pracy, dotyczącej propozycji usprawnień oraz dalszej rozbudowy oprogramowania.


\chapter{Omówienie biblioteki do pisania agentów}
W rozdziale tym zostało opisane wszystko co potrzebne, by nauczyć się używać oprogramowania napisanego na potrzeby pracy.
\section{Środowisko pisania modułu}
Podczas pisania biblioteki użyto:
\begin{itemize}
  \item System operacyjny - Ubuntu 18.04
  \item Python 3.6.7 wraz ze standardowymi modułami oraz colorama.
\end{itemize}
\section{Co wchodzi w skład biblioteki}
W skład biblioteki wchodzi:
\begin{itemize}
  \item plik agent\textunderscore module.py - jest to moduł do pythona zawierający najważniejsze funkcje/klasy.
  \item plik game\textunderscore template.py - jest to plik z szablonem gry planszowej mający na celu ułatwić projektowanie gry.
  \item ox.py, connect4.py, fox\textunderscore game.py, reversi.py - przykłady tworzenia gier planszowych
\end{itemize}


\section{Omówienie zasad przykładowych gier}
Poniżej zostały przedstawione zasady gier, które są zaimplementowane jako przykłady.
\subsection{Kółko i krzyżyk}
Gra odbywa się na planszy 3x3.
Jeden gracz umieszcza na planszy kółka, drugi zaś krzyżyki.
Gracze wykonują ruchy naprzemiennie. Celem gry jest ułożenie, jako pierwszy, trzech pionków w pionie, poziomie lub na skosie.
Poniżej na rysunku, pożyczonym z  wikipedii, widać zakończoną grę.
Zwycięzcą jest gracz stawiający kółka.

\begin{figure}[H]
  \includegraphics{./images/tictactoe.png}
  \centering
  \caption{kółko i krzyżyk}
  \label{fig:ox}
\end{figure}

Przykładowa implementacja tej gry znajduje się w pliku ox.py.
Kod programu do tej gry został też szczegółowo omówiony w dalszej części tej pracy.

\subsection{Connect Four}
W grze o nazwie Connect Four celem gracza jest takie ułożenie na planszy, żeby 4 jego pionki były połączone, podobnie jak w grze kółko i krzyżk, w pionie, poziomie lub skosie.
Gracze wrzucają swoje pionki naprzemiennie od góry planszy.
Poniżej na rysunkach, zapożyczonych z wikipedii, widać przykładowy zestaw do gry - pionowa plansza z otworami na górze - do wrzucania pionków.

\begin{figure}[H]
  \includegraphics[scale=0.25]{./images/connect4.jpg}
  \centering
  \caption{Connect Four, Zakończona gra}
  \label{fig:c4}
\end{figure}
\begin{figure}[H]
  \includegraphics[scale=0.5]{./images/connect4.png}
  \centering
  \caption{Connect Four, W trakcie gry}
  \label{fig:c4_2}
\end{figure}

Na rysunku 3.3 widać grę, która jeszcze nie jest skończona.
Ruch ma grach zaczynający. Na potrzeby tłumaczenia załóżmy, że ruch ma teraz gracz czerwony.
Zgodnie z zasadami może on wybrać dowolną kolumnę i wrzucić tam swój pionek.
Zarówno gracz żółty jak i czerwony, mają po 3 pionki ułożone na skosie, które mogą spróbować ułożyć na wygraną (4 pionki na skos).


\subsection{Lis i Gęsi}
Tutaj zostanie omówiony podstawowy wariant gry - z jednym lisem i trzynastoma gęsiami.
Jest to prosta gra dwuosobowa. Jeden gracz zarządza Lisem, drugi gęsiami.
Gra toczy się na planszy w kształcie krzyża.
Celem Lisa jest zbicie takiej liczby gęsi by nie mogły one wygrać (przyjmuje się, że 8 jest wystarczające).
Lis potrafi się poruszać po planszy oraz bić gęsi na takich samych zasadach jak w warcabach.
Celem Gęsi jest uwięzienie lisa - doprowadzenie do takiej sytuacji, że lis nie może się ruszyć ani zbić gęsi.
Gęsi w odróżnienu od lisa mogą się tylko przemieszczać na sąsiednie wolne pola.
Grę rozpoczynają gęsi.
Poniżej na rysunku z wikipedii, widoczny jest wariant tej gry z dwoma lisami i większą ilością gęsi.
\begin{figure}[H]
  \includegraphics[scale=0.25]{./images/foxgames.jpg}
  \centering
  \caption{Fox Games}
  \label{fig:fg}
\end{figure}

Przykładowa implementacja tej gry znajduje się w pliku fox\textunderscore game.py

\subsection{Reversi}
Kolejną i ostatnią grą implementowaną na potrzeby tej pracy jest gra o nazwie reversi.
Gra odbywa się na planszy 8x8.
W grze tej jest dwóch graczy wykonujących swoje ruchy naprzemiennie.
Gracz zaczynający gra pionkami czarnymi, drugi gracz gra pionkami białymi.
Jeżeli któryś z graczy nie może wykonać poprawnego ruchu, wtedy traci turę.
Gra kończy się, gdy żaden z graczy nie może wykonać poprawnego ruchu.
Jeśli gracz chce wygrać powinien na zakończeniu gry mieć więcej własnych pionków niż przeciwnik.

Teraz zostanie omówiony prawidłowy sposób wykonywania tury.
Jedyny ruch jaki można w tej grze wykonywać to dokładanie pionka.
Dokładanie pionka może odbywać się tylko w taki sposób, że tworzy linię (poziomą, pionową lub ukośną) z innym swoim pionkiem na początku (na drugim końcu lini), a pionkiem/ami przeciwnika pomiędzy (pomiędzy początkiem a pionkiem dołożonym mogą i muszą znajdować się tylko pionki przeciwnika).
Pionki przeciwnika znajdujące się na tej lini zmieniają kolor na kolor pionków gracza dokładającego.
W oczywisty sposób jednym ruchem można utworzyć więcej niż jedną taką linię - co bywa korzystne.
Poniżej na rysunkach z wikipedii zanajdują się kolejno sytuacja początkowa oraz pokazane możliwe ruchy.
\begin{figure}[H]
  \includegraphics{./images/reversi.png}
  \centering
  \caption{Reversi, stan początkowy}
  \label{fig:reversi}
\end{figure}

\begin{figure}[H]
  \includegraphics[scale=0.66]{./images/reversi_moves.png}
  \centering
  \caption{Reversi, W kolorze szarym oznaczono możliwe do wykonania ruchy czarnych pionków}
  \label{fig:reversi_moves}
\end{figure}

Przykładowa implementacja tej gry znajduje się w pliku reversi.py


\section{Omówienie szablonu gier planszowych}
Swoją pracę z omawianą biblioteką powinno się zacząć od zrozumienia pliku game\textunderscore template.py.
Na wstępie warto powiedzieć, że prawidłowe korzystanie z tego pliku polega na skopiowaniu go i poprawnym wyedytowaniu na potrzeby nowej gry.

\subsection{class GameTemplate}
W pliku tym znajduje się klasa GameTemplate jest to najważniejsza część tego pliku.
Jak można zauważyć klasa ta zawiera wiele metod - nazwy tych metod nie powinny być zmieniane, ponieważ agent\textunderscore module.py korzysta z nich w swoich funkcjach.
Klasa ta to abstrakcyjny model gry planszowej - zawierający wszystkie niezbędne funkcje - które powinno się zaimplementować.

\subsection{Przykładowe AI}
W tym samym pliku, poniżej wcześniej wspomnianej klasy - można znaleźć klasę NPCPlayer. Ten przykład jest bardzo prosty - jest to zwykły agent grający losowo.
W tym miejscu warto wspomnieć, że nasz moduł do agentów wykorzystuje pole player\textunderscore id - powinien być to unikatowy id dla agenta - niekoniecznie to musi być, jak w przykładzie, jego pionek.
Niemniej jednak na potrzeby funkcji z agenta to pole powinno być zapewnione.

Na końcu tego pliku widać dwie linijki kodu, które odpowiadają za inicjalizacje oraz uruchomienie gry.
\section{Propozycja implementowania gier planszowych}
Dla ułatwienia pisania programu oraz szybkiego zapoznania się z biblioteką warto omówić rutynowe czynności, które występują przy pracy z omawianą biblioteką.
Poniżej omówione są dwie zawsze występujące, rutynowe, czynności.
\subsection{Tworzenie gry planszowej}
Tworzenie gry planszowej przy pomocy tej biblioteki sprowadza się do:
\begin{itemize}
  \item Zmiany nazwy klasy GameTemplate na nazwę gry
  \item implementacji logiki gry w metodach tej klasy (zgodnie z komentarzami)
  \item implementacji interfejsu graficznego gry
  \item tetowania programu
\end{itemize}

\subsection{Tworzenie Agenta}
Tworzenie agenta w abstrakcyjnym ujęciu sprowadza sie do:
\begin{itemize}
  \item zmiany nazwy klasy agenta z pliku game\textunderscore template.py
  \item zapisanie logiki agenta w metodzie make\textunderscore move
\end{itemize}

\section{Opis agent\textunderscore module.py}
Plik agent\textunderscore module.py to tytułowy moduł, który ma ułatwiać pisanie sztucznej inteligencji do gier planszowych.
Warte omówienia (ze względu na użycie) są trzy klasy, które się tutaj znajdują:
\begin{itemize}
  \item GameBoard
  \item AgentAI
  \item HumanPlayer
\end{itemize}

\subsection{Klasa GameBoard}
Klasa GameBoard zawiera metody takie jak:
\begin{itemize}
  \item is\textunderscore on\textunderscore board - zwraca prawdę jeżeli dane współrzędne leżą na planszy - fałsz w przeciwnym wypadku.
  \item count\textunderscore symbol - zwraca liczbę wystąpienia znaku na planszy.
  \item is\textunderscore unoccupied - odpowiada na pytanie czy dane pole jest zajęte.
  \item is\textunderscore occupied - logiczna negacja poprzedniej metody.
  \item print\textunderscore board - funkcja do wypisywania w konsoli (znakami ascii - colorama) planszy do gry.
  Funkcja jest domyślnie skonfigurwana. 1
\end{itemize}
Sposoby użycia tej klasy są dobrze widoczne w dołączonych przykładowych grach.

\subsection{Klasa AgentAI}
Klasa AgentAI zawiera pola i metody - poniżej ważniejsze z nich.
Ważniejsze pola uzywane w funkcji init:
\begin{itemize}
  \item player\textunderscore id - unikatowe id gracza - służy do jego identyfikacji
  \item game\textunderscore heuristic - funkcja oceniająca stan gry - domyślna heurystyka symuluje losowe rozgrywki i na tej podstawie ocenia.
  \item max\textunderscore depth - maksymalna głębokość budowangeo drzewa dla funkcji takich jak minimax etc. Domyślna wartość to \( +\infty \)
  \item number\textunderscore simulations - liczba symulacji dla funkcji takich jak mcts etc. Zmienna ta jest używana także dla domyślnej heurystyki - mówi ile razy wykonać symulację zanim heurystyka zwróci wynik. Domyślna wartość to 10.
\end{itemize}

Poniżej znajdują się ważniejsze metody używane w klasie agenta.
Wszystkie poniższe funkcje mają jeden parametr - jest to aktualna gra (obiekt implementujący metody podane w klasie GameTemplate).
\begin{itemize}
  \item minimax\textunderscore move - funkcja zwraca ruch wybrany metodą MiniMax.
  \item random\textunderscore move - funkcja zwraca losowy ruch.
  \item alpha\textunderscore beta\textunderscore move - funkcja zwraca ruch wybrany algorytmem Alpha-Beta.
  \item mcts\textunderscore move - funkcja zwraca ruch wybrany przez algorytm Monte Carlo Tree Search.
  Prametry startowe (np. ilość symulacji) konfigurowane są podczas inicjalizacji agenta (np. number\textunderscore simulations).
\end{itemize}
Przykłady użycia również widoczne są w przykładowych grach np. fox\textunderscore game.py

\subsection{Klasa HumanPlayer}
Klasa HumanPlayer została zaimplementowana jako pomoc przy debugowaniu.
Jej celem jest zapewnienie minimalnej wizualizacji możliwych ruchów oraz możliwość wybrania go przez człowieka.
Klasy ta dziedziczy po AgentAI, a co więcej jest używana tak jak inni gracze w przykładowych programach.
Dla przykładu znaczy to, że aby zagrać w grę kółko i krzyży wystarczy w pliku ox.py linię:
\lstinputlisting[firstline=97,lastline=97,firstnumber=97]{../ox.py}
zamienić na:
\lstinputlisting[firstnumber=95]{humanplayer}
uprzednio importując z tego modułu klasę HumanPlayer.

\section{Omówienie kodu do gry w kółko i krzyżyk}
Na potrzeby omówienia tej pracy wybrano grę w kółko i krzyżyk.
Sama gra nie jest w żaden sposób interesująca.
Grę tą wybrano jedynie ze względu na prostotę logiki oraz zwięzłość kodu - możliwego do umieszczenia w tej pracy.
\subsection{Kod gry kółko i krzyżyk}
\lstinputlisting{../ox.py}
\subsection{Wytłumaczenie powyższego kodu}
Na początku widać klasę OX. Jest to klasa GameTemplate ze zmienioną nazwą.
Kolejno w liniach 4-11 widać inicjalizację klasy (konstruktor):
\lstinputlisting[firstline=4,lastline=11,firstnumber=4]{../ox.py}
Warto zwrócić uwagę, że na samym początku tworzymy pustą planszę do gry w kółko i krzyżyk.
kropki na naszej planszy oznaczają pola wolne.
Klasa GameBoard przyjmuje jako parametr plansze do gry (w dowolnym formacie) oraz listy symboli dla graczy - potrzebne dla funkcji print\textunderscore board.
W przypadku naszej gry jej użycie nie jest konieczne.
Sama ta klasa zapewnia najbardziej podstawowe funkcje do debugowania i wspomagające operacje na planszach typu tablica dwuwymiarowa.

Kolejna metoda klasy OX to get\textunderscore opponent
\lstinputlisting[firstline=13,lastline=17,firstnumber=13]{../ox.py}
Metoda ta ma na celu podanie przeciwnika dla podanego w parametrze gracza.
Jest to funkcja z której korzystają algorytmy takie jak alpha-beta, minimax - stąd potrzeba jej implementacji.

Dalej można znaleźć metody dwie kolejne metody wymagane przez bibliotekę:
\lstinputlisting[firstline=19,lastline=26,firstnumber=19]{../ox.py}

Pierwsza z tych funkcji get\textunderscore allowed\textunderscore moves powinna zwracać wszystkie możliwe ruchy dla danego gracza.
Format odpowiedzi to powinna być tablica ruchów właśiwie w dowolnym formacie, który jest rozumiany przez funkcję apply\textunderscore move.
W naszym wypadku gracz nie ma znaczenia, ponieważ możliwe ruchy to wolne pola na planszy (i nie zależy to od gracza).
Funkcja ta przyjmuje gracza jako argument tylko dla wymagań biblioteki.
Obydwie te funkcje są potrzebne do poprawnego działania algorytmów przeszukiwania.

Ostatnie dwie ważne funkcje to is\textunderscore winner oraz game\textunderscore end.
Pierwsza z nich odpowiada czy gracz podany jako argument jest zwycięzcą gry, druga odpowiada na pytanie czy gra jest zakończona.
Podobnie jak wyżej te funkcje są potrzebne dla wyżej wymienionych algorytmów i implementują logikę właściwą dla konkretnej gry.

Pozostała część kodu to funkcjonalności potrzebne do działania gry, stworzone w sposób opisana w poprzednim punkcie tego rozdziału.

\section{Pozostałe gry}
Pozostałe gry ze względu na swoje rozmiary nie zostały w tej pracy szczegółowo opisane.
Jednak zalecane jest zapoznanie się z kodem w nich zawartym, ze względu na:

\begin{itemize}
  \item w pliku fox\textunderscore game.py - znajduje się przykład implementacji gry o niestandardowych kształtach (plansza w kształcie krzyża). Jest tam też przykład agenta grającego mcts oraz gracz grający alpha-beta z domyślną heurystyką, gdy lis nie ma możliwości bicia przeciwnika.
  \item w pliku reversi.py znajduje się przykład mcts oraz gracza alpha-beta z niestandardową heurystyką.
  \item w pliku connect4.py jest przykład dwóch graczy grających losowo.
\end{itemize}

\section{Propozycje dalszego rozwoju biblioteki}
\subsection{Propozycje rozbudowy oprogramowania}
Poniżej przedstawiono propozycycje rozbudowy oprogramowania.
Propozycje te wykraczają poza tematyke pracy, jednak ze względu na ich wartościowość, zostały one tutaj zamieszczone.
\begin{itemize}
  \item Dodanie innych algorytmów przeszukiwania (bez adwersarza) (A*, B*, DFS, BFS (głównie z myślą o celach edukacyjnych))
  \item Przemyślenia wsparcia dla sieci neuronowych i deep learningu.
  \item Ze względu na to, że sam python działa stosunkowo wolno, a pisane programy na kursie sztucznej inteligencji są również pisane w języku C++ - stworzenie wersji blioteki w C/C++
  \item Dodanie testów automatycznych.
\end{itemize}

\subsection{Propozycje optymalizacji i usprawnień}
Poniżej przedstawiono propozycje usprawnień już zaimplementowanych algorytmów.

\subsubsection{Optymalizacje i usprawnienia algorytmu Alpha-Beta}
Implementowana wersja algorytmu Alpha-Beta jest podstawową wersją algorytmu.
Stąd możliwe są usprawnienia takie jak:
\begin{itemize}
  \item Jak już wspomniano, algorytm Alpha-Beta działa szybciej gdy przegląda ruchy w kolejności uporządkowanej.
    Ze względu na ten fakt, zanim algorytm zacznie iterację po liście zawierającym dzieci, listę tą można uporządkować, używając do porównania funkcji oceniającej.
    Zakłada się, że nawet bardzo prosta heurystyka powinna zauważalnie przyśpieszyć działanie algorytmu.
  \item zwykły algorytm MiniMax można wykonywać wielowątkowo
\end{itemize}

\subsubsection{Optymalizacje i usprawnienia algorytmu MCTS}
Implementowana wersja algorytmu Monte Carlo Tree Search jest również podstawową wersją algorytmu.
Stąd przykładowe optymalizacje to:

\begin{itemize}
  \item Zanim przejdziemy do rozbudowywania drzewa, bezsensowne ruchy można z góry odrzucić.
  \item Dla dobrych ruchów, np. ruchy wygrywające, lub wygrywające w paru ruchach (możliwe do oceny przez prostą heurystykę), można zwiększać wartość funkcji przedstawionej w pseudokodzie jako eval\textunderscore func. Taka pozornie drobna zmiana spowoduje, że algorytm będzie więcej czasu spędzał w potencjalnie dobrych ruchach.
  \item Algorytm MCTS idealnie nadaje się do bycia wspartym przez wielowątkowość.
\end{itemize}

\chapter{Zakończenie}
Jak widać cel pracy został osiągnięty - powstała biblioteka wspomagająca tworzenie inteligentnych agentów do gier planszowych.
Zaimplementowano także liczne przykłady użycia biblioteki, zgodnie z zasadą, że dostęp do kodu jest często lepszy niż szczegółowa dokumentacja.
W obecnym stanie z biblioteki korzysta się przyjemnie do tworzenia zarówno gier planszowych jak i agentów do niej.
Biblioteka została napisana z dbałością o to by zapewnić łatwość przyszłej rozbudowy.
Liczne propozycje usprawnień oraz rozbudowy, wychodzące poza zakres tej pracy, zostały przedstawione poprzednim rozdziale.


%%%%% BIBLIOGRAFIA

%\begin{thebibliography}{1}
%\bibitem{example} \ldots
%\end{thebibliography}

\end{document}
